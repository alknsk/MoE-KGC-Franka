2025-07-05 08:41:39 - moe_kgc - INFO - Logging to experiments/moe_kgc_batch_experiment/logs/moe_kgc_20250705_084139.log
2025-07-05 08:41:39 - moe_kgc - INFO - 开始实验: moe_kgc_batch_experiment
2025-07-05 08:41:39 - moe_kgc - INFO - 使用设备: cuda
2025-07-05 08:41:39 - moe_kgc - INFO - 加载数据...
2025-07-05 08:41:39 - moe_kgc - INFO - 加载预处理的PyG数据...
2025-07-05 08:41:39 - moe_kgc - INFO - 创建mini-batch数据加载器...
2025-07-05 08:41:40 - moe_kgc - INFO - 数据加载完成:
2025-07-05 08:41:40 - moe_kgc - INFO -   训练批次数: 7827
2025-07-05 08:41:40 - moe_kgc - INFO -   验证批次数: 534
2025-07-05 08:41:40 - moe_kgc - INFO -   测试批次数: 509
2025-07-05 08:41:40 - moe_kgc - INFO - 初始化模型...
2025-07-05 08:41:40 - moe_kgc - INFO - 检测到6个GPU设备
2025-07-05 08:41:47 - moe_kgc - INFO - 模型参数量: 119,262,990
2025-07-05 08:41:47 - moe_kgc - INFO - 开始训练...
2025-07-05 08:41:48 - moe_kgc - ERROR - 多模态编码错误: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 0 has a total capacity of 44.34 GiB of which 16.88 MiB is free. Process 3374624 has 22.95 GiB memory in use. Process 3374623 has 1.39 GiB memory in use. Process 3722895 has 432.00 MiB memory in use. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.16 GiB is allocated by PyTorch, and 61.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-07-05 08:41:48 - moe_kgc - WARNING - 使用node_features作为回退
